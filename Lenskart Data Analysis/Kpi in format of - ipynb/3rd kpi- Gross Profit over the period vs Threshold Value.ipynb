{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1099223-54ba-4349-8f58-8466ee322d29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls('dbfs:/mnt/blobstorage/dataset_Lenskart/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d8eb438-9b1e-462f-9b46-63e58d8c0bda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_product = spark.read.csv('dbfs:/mnt/blobstorage/dataset_Lenskart/products_tf.csv',inferSchema=True,header=True)\n",
    "df_transaction = spark.read.csv('dbfs:/mnt/blobstorage/dataset_Lenskart/transaction.csv',inferSchema=True,header=True)\n",
    "df_stores = spark.read.csv('dbfs:/mnt/blobstorage/dataset_Lenskart/stores_tf.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f8508d-dc8b-4b21-9c4c-5397dbd69ae5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_combined_tr_pd= df_transaction.join(df_product,'product_id','inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd81bd2c-d3c2-4090-91f2-fee94361100b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_combined= df_combined_tr_pd.join(df_stores,'store_id','inner')\n",
    "df_combined.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f93cb51c-893f-4e24-a15c-3ce9d6374294",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_combined= df_combined.withColumn('sales',F.col('quantity') * F.col(' price'))\n",
    "\n",
    "# Calculate sales for each product\n",
    "df_combined = df_combined.withColumn('sales', F.col('quantity') * F.col(' price'))\n",
    "\n",
    "# Calculate cost for each product\n",
    "df_combined = df_combined.withColumn('cost', F.col('quantity') * F.col('cost_of_product'))\n",
    "\n",
    "# Group by product_id and sum the sales and cost\n",
    "df_combined = df_combined.groupBy('store_id').agg(F.sum('sales').alias('total_sales'), F.sum('cost').alias('total_cost'))\n",
    "\n",
    "df_combined= df_combined.withColumn('profit',F.col('total_sales')-F.col('total_cost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac336048-9679-492c-8e51-b05b003a9444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_combined=df_combined.orderBy('profit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bde7fe5f-2602-4b33-b4be-c4e94dbf0363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_combined.display();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "934b362b-e09c-421c-bda2-9c3a003cc7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median profit: 53994.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate the median of total_sales\n",
    "median_profit = df_combined.approxQuantile('profit', [0.5], 0.0)[0]\n",
    "\n",
    "# Display the result\n",
    "print(\"Median profit:\", median_profit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c4aee4-ce50-4862-8d8b-1faff22df5c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "# Filter the DataFrame for rows where the store sales is greater than median\n",
    "df_store_sales_gt_median = df_combined.filter(df_combined[\"profit\"] > median_profit)\n",
    "# Show the resulting DataFrame\n",
    "df_store_sales_gt_median = df_store_sales_gt_median.withColumn(\"Threshold_value\",lit(median_profit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd134849-6c09-4093-9289-b083f6ee92b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_store_sales_gt_median.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cc31dce-383e-4e07-9f04-d8d4c2702e46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import lit\n",
    "df_combined = df_combined.withColumn(\"median_profit\",lit(median_profit))\n",
    "df_store_status = df_combined.withColumn(\"store_status\", expr(\"CASE WHEN profit > {0} THEN 'profitable' ELSE 'non_profitable' END\".format(median_profit)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50cb2b31-e6bc-40f4-9efa-b43ad007c686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_store_status.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ccebab1-97cd-435a-9d81-de24186a0355",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final= df_store_status.join(df_stores,'store_id','inner')\n",
    "df_final.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3rd kpi using median",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
